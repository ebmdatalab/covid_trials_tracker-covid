{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICTRP Search: \"covid-19\" or \"novel coronavirus\" or \"2019-ncov\" or \"covid19\" or \"sars-cov-2\"\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import unicodedata\n",
    "\n",
    "#POINT THIS TO THE UPDATED XML - deprecated as ICTRP is down.\n",
    "\n",
    "#with open('ICTRP-Results_18Mar2020.xml', 'rb') as f:\n",
    "#    xml = xmltodict.parse(f, dict_constructor=dict)\n",
    "\n",
    "#df = pd.DataFrame(xml['Trials_downloaded_from_ICTRP']['Trial'])\n",
    "\n",
    "#This now takes the CSV posted by the ICTRP as an input from here: https://www.who.int/ictrp/en/\n",
    "\n",
    "df = pd.read_excel('this_weeks_data/covid-19-trials_25Mar2020.xlsx', dtype={'Phase': str})\n",
    "\n",
    "#UPDATE THESE WITH EACH RUN\n",
    "prior_extract_date = date(2020,3,18)\n",
    "this_extract_date = date(2020,3,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only what we need right now\n",
    "\n",
    "cols = ['TrialID', 'Source Register', 'Date registration', 'Date enrollement', 'Primary sponsor', \n",
    "        'Recruitment Status', 'Phase', 'Study type', 'Countries', 'Public title', 'Intervention',\n",
    "        'web address', 'results url link', 'Last Refreshed on']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "#renaming columns to match old format so I don't have to change them throughout\n",
    "df_cond.columns = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', \n",
    "                   'Primary_sponsor', 'Recruitment_Status', 'Phase', 'Study_type', 'Countries', \n",
    "                   'Public_title', 'Intervention', 'web_address', 'results_url_link', \n",
    "                   'Last_Refreshed_on']\n",
    "\n",
    "print(f'Search on ICTRP reveals {len(df_cond)} trials as of {this_extract_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT THIS TO LAST WEEK'S DATA\n",
    "last_weeks_trials = pd.read_csv('last_weeks_data/trial_data_18_mar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining in the 'first_seen' field\n",
    "df_cond = df_cond.merge(last_weeks_trials[['trialid', 'first_seen']], left_on = 'TrialID', right_on = 'trialid', \n",
    "                        how='left').drop('trialid', axis=1)\n",
    "\n",
    "#Adding the `first_seen` field to new trials\n",
    "df_cond['first_seen'] = pd.to_datetime(df_cond['first_seen'].fillna(this_extract_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for which registries we are dealing with:\n",
    "df_cond.Source_Register.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with data straight from XML we need to do some tedious tidying up of dates because of different formats. They do not parse correctly by default in Pandas. They are standardized, however, in the ICTRP spreadsheet so I have removed this code for now. It is archived in old commits to the GitHub repo for future refrence if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get rid of trials from before 2020 for now\n",
    "\n",
    "pre_2020 = len(df_cond[df_cond['Date_registration'] < pd.Timestamp(2020,1,1)])\n",
    "\n",
    "print(f'Excluded {pre_2020} trials from before 2020')\n",
    "\n",
    "df_cond_rec = df_cond[df_cond['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_rec)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code removes trials that indicate that they never started. This is done on the Chinese registry through specific language in the Title. Trials from ClinicalTrials.gov are indicated by the `Withdrawn` trial status. \n",
    "\n",
    "This will be expanded moving forward to account for the unique terminology used by other registries as necessary moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cancelled/withdrawn trials for what registries we have to date\n",
    "\n",
    "cancelled_trials = len(df_cond_rec[(df_cond_rec['Public_title'].str.contains('Cancelled')) | \n",
    "                                   (df_cond_rec['Public_title'].str.contains('Retracted due to')) | \n",
    "                                   (df_cond_rec['Recruitment_Status'] == \"Withdrawn\")])\n",
    "\n",
    "print(f'Excluded {cancelled_trials} cancelled trials with no enrollment')\n",
    "\n",
    "#Now lets get rid of trials we know don't belong from manual review, reason catalogued below\n",
    "#NCT04226157 Non-COVID trial delayed because of COVID and put this in the title\n",
    "#NCT04246242 This trial registration doesn't exist anymore\n",
    "\n",
    "exclude = ['NCT04226157', 'NCT04246242']\n",
    "\n",
    "print(f'Excluded {len(exclude)} non-COVID trials screened through manual review')\n",
    "\n",
    "df_cond_nc = df_cond_rec[~((df_cond_rec['Public_title'].str.contains('Cancelled')) | \n",
    "                           (df_cond_rec['Public_title'].str.contains('Retracted due to'))) & \n",
    "                         ~(df_cond_rec['Recruitment_Status'] == \"Withdrawn\") &\n",
    "                         ~(df_cond_rec['TrialID'].isin(exclude))].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_nc)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to take a quick look at trials that came and went since the last update. We can add in any additional trials that we know about that are not accounted for in the ICTRP database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for checking changes\n",
    "\n",
    "def trial_diffs(new=True):\n",
    "    df = df_cond_nc.merge(last_weeks_trials['trialid'], left_on = 'TrialID', right_on = 'trialid', how='outer', indicator=True)\n",
    "    if new:\n",
    "        new = df[(df['_merge'] == 'left_only')]\n",
    "        return new['TrialID'].tolist()\n",
    "    else:\n",
    "        dropped = df[(df['_merge'] == 'right_only')]\n",
    "        return dropped['trialid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(trial_diffs(new=True))} new trials')\n",
    "\n",
    "print(f'The following trials were removed since the last time and were manually checked:')\n",
    "print(trial_diffs(new=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additions = pd.read_excel('manual_data.xlsx', sheet_name = 'additional_trials')\n",
    "\n",
    "print(f'An additional {len(additions)} known trials were not in the ICTRP data')\n",
    "\n",
    "print(set(additions['TrialID'].tolist()).difference(df_cond_nc['TrialID'].tolist()))\n",
    "\n",
    "df_cond_nc = df_cond_nc.append(additions)\n",
    "\n",
    "print(f'The final dataset is {len(df_cond_nc)} trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation and data cleaning of all fields. This will be expanded each update as more trials get added and more registries start to add trials with their own idiosyncratic data categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A small function to help quickly check the contents of various columns\n",
    "\n",
    "def check_fields(field):\n",
    "    return df_cond_nc[field].unique()\n",
    "\n",
    "#Check fields for new unique values that require normalisation\n",
    "check_fields('Study_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning various fields. \n",
    "#One important thing we have to do is make sure there are no nulls or else the data won't properly load onto the website\n",
    "\n",
    "#Can't have nulls in the results field. Might need to move this later on when we start populating results\n",
    "df_cond_nc['results_url_link'] = df_cond_nc['results_url_link'].fillna('No Results')\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_nc['Intervention'] = df_cond_nc['Intervention'].str.replace(';', '')\n",
    "\n",
    "#phase\n",
    "df_cond_nc['Phase'] = df_cond_nc['Phase'].fillna('Not Applicable')\n",
    "phase_fixes = {'0':'Not Applicable', '1':'Phase 1', '2':'Phase 2', '3':'Phase 3', '4':'Phase 4', \n",
    "               '1-2':'Phase 1/Phase 2', 'Retrospective study':'Not Applicable', \n",
    "               'Not applicable':'Not Applicable',\n",
    "               'New Treatment Measure Clinical Study':'Not Applicable', \n",
    "               '2020-02-01 00:00:00':'Phase 1/Phase 2',\n",
    "               '2020-03-02 00:00:00':'Phase 2/Phase 3', 'Phase III':'Phase 3',\n",
    "               'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n': 'Phase 2',\n",
    "               'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n': 'Phase 3'\n",
    "              }\n",
    "df_cond_nc['Phase'] = df_cond_nc['Phase'].replace(phase_fixes)\n",
    "\n",
    "#Study Type\n",
    "obv_replace = ['Observational [Patient Registry]', 'observational']\n",
    "int_replace = ['interventional', 'Interventional clinical trial of medicinal product', 'Treatment']\n",
    "\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].str.replace(' study', '')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace(obv_replace, 'Observational')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace(int_replace, 'Interventional')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace('Epidemilogical research', 'Epidemiological research')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace('Health services reaserch', 'Health services research')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].fillna('No Status Given')\n",
    "\n",
    "#Get rid of messy accents\n",
    "\n",
    "def norm_names(x):\n",
    "    normed = unicodedata.normalize('NFKD', str(x)).encode('ASCII', 'ignore').decode()\n",
    "    return normed \n",
    "\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc.Primary_sponsor.apply(norm_names)\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('nan', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Countries\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].fillna('No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china']\n",
    "\n",
    "country_values = df_cond_nc['Countries'].tolist()\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for c in country_values:\n",
    "    country_list = []\n",
    "    if isinstance(c, float):\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c == 'No Sponsor Name Given':\n",
    "        country_list.append('No Sponsor Name Given')\n",
    "    elif c in china_corr:\n",
    "        country_list.append('China')\n",
    "    elif c == 'Iran (Islamic Republic of)':\n",
    "        country_list.append('Iran')\n",
    "    elif c == 'Korea, Republic of':\n",
    "        country_list.append('South Korea')\n",
    "    elif c == 'Japan,Asia(except Japan),Australia,Europe':\n",
    "        country_list = ['Japan', 'Australia', 'Asia', 'Europe']\n",
    "    elif ';' in c:\n",
    "        c_list = c.split(';')\n",
    "        unique_values = list(set(c_list))\n",
    "        for v in unique_values:\n",
    "            if v == 'Iran (Islamic Republic of)':\n",
    "                country_list.append('Iran')\n",
    "            elif v == 'Korea, Republic of':\n",
    "                country_list.append('South Korea')\n",
    "            else:\n",
    "                country_list.append(v)\n",
    "    else:\n",
    "        country_list.append(c)\n",
    "    new_list.append(', '.join(country_list))\n",
    "\n",
    "df_cond_nc['Countries'] = new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last space for manual intervention. This will include manual normalisation of new names, any updates to the normalisation schedule from the last update, and updating manually-coded intervention type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing sponsor names\n",
    "#Run this cell, updating the spon_norm csv you are loading after manual adjusting\n",
    "#until you get the 'All sponsor names normalized' to print\n",
    "\n",
    "spon_norm = pd.read_excel('manual_data.xlsx', sheet_name = 'sponsor')\n",
    "\n",
    "df_cond_norm = df_cond_nc.merge(spon_norm, left_on = 'Primary_sponsor', right_on ='unique_spon_names', how='left')\n",
    "df_cond_norm = df_cond_norm.drop('unique_spon_names', axis=1)\n",
    "\n",
    "new_unique_spon_names = (df_cond_norm[df_cond_norm['normed_spon_names'].isna()][['Primary_sponsor', 'TrialID']]\n",
    "                        .groupby('Primary_sponsor').count())\n",
    "\n",
    "if len(new_unique_spon_names) > 0:\n",
    "    new_unique_spon_names.to_csv('to_norm.csv')\n",
    "    print('Update the normalisation schedule and rerun')\n",
    "else:\n",
    "    print('All sponsor names normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating intervention type data\n",
    "#Once again, run to bring in the old int-type data, islolate the new ones, update, and rerun until\n",
    "#producing the all-clear message\n",
    "\n",
    "int_type = pd.read_excel('manual_data.xlsx', sheet_name = 'intervention')\n",
    "df_cond_int = df_cond_norm.merge(int_type[['trial_id', 'intervention_type', 'intervention']], left_on = 'TrialID', right_on = 'trial_id', how='left')\n",
    "df_cond_int = df_cond_int.drop('trial_id', axis=1)\n",
    "\n",
    "new_int_trials = df_cond_int[(df_cond_int['intervention_type'].isna()) | (df_cond_int['intervention'].isna())]\n",
    "\n",
    "if len(new_int_trials) > 0:\n",
    "    new_int_trials[['TrialID', 'Public_title', 'Intervention', 'intervention_type', 'intervention']].to_csv('int_to_assess.csv')\n",
    "    print('Update the intervention type assessments and rerun')\n",
    "else:\n",
    "    print('All intervention types matched')\n",
    "    df_cond_int = df_cond_int.drop('Intervention', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final organising\n",
    "\n",
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_int.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_int.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'normed_spon_names', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', 'intervention_type', 'intervention',\n",
    "           'web_address', 'results_url_link', 'last_refreshed_on', 'first_seen']\n",
    "\n",
    "df_final = df_cond_int[reorder].reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any null values\n",
    "df_final[df_final.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick look at the data\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export final dataset\n",
    "df_final.to_csv(f'processed_data_sets/trial_list_{this_extract_date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export json for website\n",
    "import json\n",
    "with open(\"website_data/trials_latest.json\", \"w\") as f:\n",
    "    json.dump({\"data\": df_final.astype(str).values.tolist()}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Trend in Registered Trials Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "just_reg = df_final[['trialid', 'date_registration']].reset_index(drop=True)\n",
    "#just_reg = mar18[['trialid', 'date_registration']].reset_index(drop=True)\n",
    "#just_reg['date_registration'] = pd.to_datetime(just_reg['date_registration'], format='%d/%m/%Y')\n",
    "\n",
    "#catch old registrations that were expanded to include COVID, we can get rid of these for now\n",
    "just_reg = just_reg[just_reg['date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_reg.index = just_reg['date_registration']\n",
    "\n",
    "\n",
    "grouped = just_reg.resample('W').count()\n",
    "cumsum = grouped.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = []\n",
    "\n",
    "for x in list(grouped.index):\n",
    "    labels.append(str(x.date()))\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), dpi = 300)\n",
    "\n",
    "l1 = plt.plot(x_pos, grouped['trialid'], marker = 'o')\n",
    "l2 = plt.plot(x_pos, cumsum['trialid'], marker = 'o')\n",
    "\n",
    "for i, j in zip(x_pos[1:], grouped['trialid'].tolist()[1:]):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.1, j-35))\n",
    "\n",
    "for i, j in zip(x_pos, cumsum['trialid']):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.2, j+20))\n",
    "    \n",
    "\n",
    "gr = grouped['trialid'].to_list()\n",
    "cs = cumsum['trialid'].to_list()\n",
    "\n",
    "plt.xticks(x_pos, labels, rotation=45, fontsize=8)\n",
    "plt.ylim(-50,800)\n",
    "plt.xlabel('Week Ending Date')\n",
    "plt.ylabel('Registered Trials')\n",
    "plt.title('Registered COVID-19 Trials by Week on the ICTRP')\n",
    "plt.legend(('New Trials', 'Cumulative Trials'), loc=2)\n",
    "#plt.savefig(f'trial_count_{last_extract_date}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=labels, y=grouped['trialid'], fill=None, name='New Trials'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=labels, y=cumsum['trialid'], fill=None, name='Cumulative Trials'))\n",
    "\n",
    "fig.update_layout(title={'text': 'Registered COVID-19 Trials by Week', 'xanchor': 'center', 'x': 0.5}, \n",
    "                  xaxis_title='Week Ending Date',\n",
    "                  yaxis_title='Registered Trials',\n",
    "                  legend = dict(x=0, y=1, traceorder='normal', bgcolor='rgba(0,0,0,0)'))\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html(\"registered trials.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "int_types = df_final.intervention_type.value_counts()\n",
    "\n",
    "treatment_dict = dict(drugs = int_types['Drug'], \n",
    "                      atmp = int_types['ATMP'], \n",
    "                      clinical_char = int_types['Clinical Presentation'] + int_types['Diagnosis'] + int_types['Prognosis'],\n",
    "                      drug_other_combo = int_types['Drug (+ATMP +Other (renal))'] + int_types['Drug (+ATMP)'],\n",
    "                      supp = int_types['Supplement'],\n",
    "                      geno = int_types['Genomics'],\n",
    "                      tm = int_types[[s.startswith('Traditional Medicine') for s in int_types.index]].sum(),\n",
    "                      other = int_types[[s.startswith('Other') for s in int_types.index]].sum()\n",
    "                     )\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "            x=list(treatment_dict.values()),\n",
    "            y=['Drugs', 'ATMP', 'Clinical Characteristics', 'Drug + Other Therapy', 'Supplement', 'Genomics', 'Traditional Medicine', 'Other'],\n",
    "            orientation='h'))\n",
    "\n",
    "fig.update_layout(title={'text': 'Intervention Type of Registered Trials', 'xanchor': 'center', 'x': 0.5}, \n",
    "                  xaxis_title='Number of Trials')\n",
    "\n",
    "fig.show()\n",
    "#fig.write_html('int_bar.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

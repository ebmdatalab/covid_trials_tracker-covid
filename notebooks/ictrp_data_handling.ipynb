{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICTRP Search: \"covid-19\" or \"novel coronavirus\" or \"2019-ncov\" or \"covid19\" or \"sars-cov-2\"\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import unicodedata\n",
    "\n",
    "#POINT THIS TO THE UPDATED XML\n",
    "#with open('ICTRP-Results_18Mar2020.xml', 'rb') as f:\n",
    "#    xml = xmltodict.parse(f, dict_constructor=dict)\n",
    "\n",
    "#df = pd.DataFrame(xml['Trials_downloaded_from_ICTRP']['Trial'])\n",
    "\n",
    "\n",
    "df = pd.read_excel('covid-19-trials_25Mar2020.xlsx', dtype={'Phase': str})\n",
    "\n",
    "#UPDATE THESE WITH EACH RUN\n",
    "prior_extract_date = date(2020,3,18)\n",
    "this_extract_date = date(2020,3,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialID</th>\n",
       "      <th>Date enrollement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT04246242</td>\n",
       "      <td>2020-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChiCTR2000029949</td>\n",
       "      <td>2020-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChiCTR2000029953</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChiCTR2000029935</td>\n",
       "      <td>2020-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChiCTR2000029947</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TrialID Date enrollement\n",
       "0       NCT04246242       2020-01-25\n",
       "1  ChiCTR2000029949       2020-02-16\n",
       "2  ChiCTR2000029953       2020-02-01\n",
       "3  ChiCTR2000029935       2020-02-06\n",
       "4  ChiCTR2000029947       2020-03-01"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['TrialID', 'Date enrollement']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search on ICTRP reveals 667 trials as of 2020-03-25\n"
     ]
    }
   ],
   "source": [
    "#For future:\n",
    "#Can try and parse the 'Target_size' variable, difficult for the Chinese registry\n",
    "\n",
    "cols = ['TrialID', 'Source Register', 'Date registration', 'Date enrollement', 'Primary sponsor', \n",
    "        'Recruitment Status', 'Phase', 'Study type', 'Countries', 'Public title', 'Intervention',\n",
    "        'web address', 'results url link', 'Last Refreshed on']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "df_cond.columns = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', \n",
    "                   'Primary_sponsor', 'Recruitment_Status', 'Phase', 'Study_type', 'Countries', \n",
    "                   'Public_title', 'Intervention', 'web_address', 'results_url_link', \n",
    "                   'Last_Refreshed_on']\n",
    "\n",
    "print(f'Search on ICTRP reveals {len(df_cond)} trials as of {this_extract_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT THIS TO LAST WEEK'S DATA\n",
    "last_weeks_trials = pd.read_csv('trial_data_18_mar.csv')\n",
    "\n",
    "df_cond = df_cond.merge(last_weeks_trials[['trialid', 'first_seen']], left_on = 'TrialID', right_on = 'trialid', \n",
    "                        how='left').drop('trialid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For next time\n",
    "df_cond['first_seen'] = pd.to_datetime(df_cond['first_seen'].fillna(this_extract_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChiCTR                             524\n",
       "ClinicalTrials.gov                 121\n",
       "IRCT                                 8\n",
       "JPRN                                 5\n",
       "EU Clinical Trials Register          3\n",
       "ISRCTN                               2\n",
       "TCTR                                 2\n",
       "German Clinical Trials Register      1\n",
       "Netherlands Trial Register           1\n",
       "Name: Source_Register, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for which registries we are dealing with:\n",
    "df_cond.Source_Register.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first area where we may need manual intervention on updates. As more registries start to appear, there may be dates in new formats that we need to address. Just running a date parse over the column, even with just two registries, was already producing wonky dates so I had to split it by registry. Check this based on the registries above and adjust.\n",
    "\n",
    "It looks like this is now standardized well enough in the ICTRP excel file that pandas can parse right on loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#last refreshed date parse\n",
    "df_cond['Last_Refreshed_on'] = pd.to_datetime(df_cond['Last_Refreshed_on'])\n",
    "\n",
    "#cleaning up registration dates\n",
    "\n",
    "date_parsing_reg = df_cond[['TrialID', 'Date_registration']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_registration'], format='%d/%m/%Y')\n",
    "\n",
    "chictr = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_registration'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_reg = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_reg = nct_merged_reg.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_registration'] = chi_merged_reg['parsed_date_x'].fillna(chi_merged_reg['parsed_date_y'])\n",
    "\n",
    "#cleaning up start dates\n",
    "\n",
    "date_parsing_enr = df_cond[['TrialID', 'Date_enrollement']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_enrollement'])\n",
    "\n",
    "chictr = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_enrollement'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_enr = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_enr = nct_merged_enr.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_enrollement'] = chi_merged_enr['parsed_date_x'].fillna(chi_merged_enr['parsed_date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 1 trials from before 2020\n",
      "666 trials remain\n"
     ]
    }
   ],
   "source": [
    "#lets get rid of trials from before 2020 for now\n",
    "\n",
    "pre_2020 = len(df_cond[df_cond['Date_registration'] < pd.Timestamp(2020,1,1)])\n",
    "\n",
    "print(f'Excluded {pre_2020} trials from before 2020')\n",
    "\n",
    "df_cond_rec = df_cond[df_cond['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_rec)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2 for manual intervention. As more registries add trials, we will have to contend with a wider vocabulary/identification methods for trials that are cancelled/withdrawn.\n",
    "\n",
    "No further conflicts as of 25 Mar 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 41 cancelled trials with no enrollment\n",
      "625 trials remain\n"
     ]
    }
   ],
   "source": [
    "#Removing cancelled/withdrawn trials for what registries we have to date\n",
    "\n",
    "cancelled_trials = len(df_cond_rec[(df_cond_rec['Public_title'].str.contains('Cancelled')) | \n",
    "                         (df_cond_rec['Recruitment_Status'] == \"Withdrawn\")])\n",
    "\n",
    "print(f'Excluded {cancelled_trials} cancelled trials with no enrollment')\n",
    "\n",
    "df_cond_nc = df_cond_rec[~(df_cond_rec['Public_title'].str.contains('Cancelled')) & \n",
    "                         ~(df_cond_rec['Recruitment_Status'] == \"Withdrawn\")].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_nc)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point three for manual intervention. All this normalisation and data cleaning will have to be expanded each update as more trials get added and more registries start to add trials with their own idiosyncratic data categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Interventional', 'Observational study', 'Interventional study',\n",
       "       'Diagnostic test', 'Observational', 'Basic Science', 'Prevention',\n",
       "       'Prognosis study', 'Treatment study', 'Epidemilogical research',\n",
       "       'Health services reaserch', 'Expanded Access', 'Screening',\n",
       "       'Observational [Patient Registry]',\n",
       "       'Interventional clinical trial of medicinal product',\n",
       "       'interventional', 'observational'], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_fields(field):\n",
    "    return df_cond_nc[field].unique()\n",
    "\n",
    "#Check fields for new unique values that require normalisation\n",
    "check_fields('Study_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'China', 'France', 'Wuhan', 'Chinese', 'china', 'Hong Kong',\n",
       "       'Chian', 'China?', 'United States',\n",
       "       'United States;Hong Kong;Korea, Republic of;Singapore;Taiwan;Hong Kong;Korea, Republic of;Singapore;Taiwan;United States',\n",
       "       'United States;Korea, Republic of;Singapore;Korea, Republic of;Singapore;United States',\n",
       "       'Korea, Republic of', 'Singapore', 'Jordan',\n",
       "       'United States;Israel;United States', 'Italy', 'Romania', 'Sweden',\n",
       "       'United Kingdom', 'Iran (Islamic Republic of)',\n",
       "       'Iran (Islamic Republic of);Iran (Islamic Republic of);Iran (Islamic Republic of)',\n",
       "       'The Netherlands', 'Germany', 'France;France', 'Japan',\n",
       "       'Japan,Asia(except Japan),Australia,Europe'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to think about fixing this\n",
    "list(check_fields('Countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More data cleaning\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_nc['Intervention'] = df_cond_nc['Intervention'].str.replace(';', '')\n",
    "\n",
    "#phase\n",
    "df_cond_nc['Phase'] = df_cond_nc['Phase'].fillna('Not Applicable')\n",
    "phase_fixes = {'0':'Not Applicable', '1':'Phase 1', '2':'Phase 2', '3':'Phase 3', '4':'Phase 4', \n",
    "               '1-2':'Phase 1/Phase 2', 'Retrospective study':'Not Applicable', \n",
    "               'Not applicable':'Not Applicable',\n",
    "               'New Treatment Measure Clinical Study':'Not Applicable', \n",
    "               '2020-02-01 00:00:00':'Phase 1/Phase 2',\n",
    "               '2020-03-02 00:00:00':'Phase 2/Phase 3', 'Phase III':'Phase 3',\n",
    "               'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): yes\\nTherapeutic confirmatory - (Phase III): no\\nTherapeutic use (Phase IV): no\\n': 'Phase 2',\n",
    "               'Human pharmacology (Phase I): no\\nTherapeutic exploratory (Phase II): no\\nTherapeutic confirmatory - (Phase III): yes\\nTherapeutic use (Phase IV): no\\n': 'Phase 3'\n",
    "              }\n",
    "df_cond_nc['Phase'] = df_cond_nc['Phase'].replace(phase_fixes)\n",
    "\n",
    "#Study Type\n",
    "obv_replace = ['Observational [Patient Registry]', 'observational']\n",
    "int_replace = ['interventional', 'Interventional clinical trial of medicinal product', 'Treatment']\n",
    "\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].str.replace(' study', '')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace(obv_replace, 'Observational')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace(int_replace, 'Interventional')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].fillna('No Status Given')\n",
    "\n",
    "#Countries\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].fillna('No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china']\n",
    "\n",
    "for c in china_corr:\n",
    "    df_cond_nc['Countries'] = df_cond_nc['Countries'].replace(c, 'China')\n",
    "    \n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('United States;Korea, Republic of;United States', \n",
    "                                                          'South Korea; United States')\n",
    "\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('Korea, Republic of', 'South Korea')\n",
    "\n",
    "#Get rid of messy accents\n",
    "\n",
    "def norm_names(x):\n",
    "    normed = unicodedata.normalize('NFKD', str(x)).encode('ASCII', 'ignore').decode()\n",
    "    return normed \n",
    "\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc.Primary_sponsor.apply(norm_names)\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('nan', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last space for manual intervention. This will include manual normalisation of new names, any updates to the normalisation schedule from the last update, and updating manually-coded intervention type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sponsor names normalized\n"
     ]
    }
   ],
   "source": [
    "#Normalizing sponsor names\n",
    "#Run this cell, updating the spon_norm csv you are loading after manual adjusting\n",
    "#until you get the 'All sponsor names normalized' to print\n",
    "\n",
    "spon_norm = pd.read_csv('norm_schedule_25Mar2020.csv')\n",
    "\n",
    "df_cond_norm = df_cond_nc.merge(spon_norm, left_on = 'Primary_sponsor', right_on ='unique_spon_names', how='left')\n",
    "df_cond_norm = df_cond_norm.drop('unique_spon_names', axis=1)\n",
    "\n",
    "new_unique_spon_names = (df_cond_norm[df_cond_norm['normed_spon_names'].isna()][['Primary_sponsor', 'TrialID']]\n",
    "                        .groupby('Primary_sponsor').count())\n",
    "\n",
    "if len(new_unique_spon_names) > 0:\n",
    "    new_unique_spon_names.to_csv('to_norm.csv')\n",
    "    print('Update the normalisation schedule and rerun')\n",
    "else:\n",
    "    print('All sponsor names normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interim dataset\n",
    "\n",
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_norm.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_norm.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'normed_spon_names', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title',\n",
    "           'web_address', 'results_url_link', 'last_refreshed_on', 'first_seen']\n",
    "\n",
    "df_cond_norm[reorder].to_csv('trial_data_25_mar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar18 = pd.read_csv('trial_data_18_mar.csv')\n",
    "mar18['results_url_link'] = mar18['results_url_link'].fillna('No Results')\n",
    "mar18['phase'] = mar18['phase'].fillna('Not Applicable')\n",
    "mar18['recruitment_status'] = mar18['recruitment_status'].fillna('No Status Given')\n",
    "\n",
    "import json\n",
    "with open(\"trials_18mar\", \"w\") as f:\n",
    "    json.dump({\"data\": mar18.values.tolist()}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating intervention type data\n",
    "#Once again, run to bring in the old int-type data, islolate the new ones, update, and rerun until\n",
    "#producing the all-clear message\n",
    "\n",
    "int_type = pd.read_csv('int_type_data_8mar2020.csv')\n",
    "df_cond_int = df_cond_norm.merge(int_type, left_on = 'TrialID', right_on = 'trial_id', how='left')\n",
    "df_cond_int = df_cond_int.drop('trial_id', axis=1)\n",
    "\n",
    "new_int_trials = df_cond_int[df_cond_int['intervention_type'].isna()]\n",
    "\n",
    "if len(new_int_trials) > 0:\n",
    "    new_int_trials[['TrialID', 'Public_title', 'Intervention', 'intervention_type']].to_csv('int_to_assess.csv')\n",
    "    print('Update the intervention type assessments and rerun')\n",
    "else:\n",
    "    print('All intervention types matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick glance at old trials that updated\n",
    "\n",
    "df_cond_int[(df_cond_int['Last_Refreshed_on'] > pd.Timestamp(prior_extract_date)) & \n",
    "            (df_cond_int['first_seen'] != this_extract_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_int.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_int.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'normed_spon_names', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', 'intervention_type', \n",
    "           'web_address', 'results_url_link', 'last_refreshed_on', 'first_seen']\n",
    "\n",
    "df_final = df_cond_int[reorder].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final.to_csv(f'trial_list_{this_extract_date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Trend in Registered Trials Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_reg = df_final[['trialid', 'date_registration']].reset_index(drop=True)\n",
    "\n",
    "#catch old registrations that were expanded to include COVID, we can get rid of these for now\n",
    "just_reg = just_reg[just_reg['date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "just_reg.index = just_reg['date_registration']\n",
    "\n",
    "\n",
    "grouped = just_reg.resample('W').count()\n",
    "cumsum = grouped.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = []\n",
    "\n",
    "for x in list(grouped.index):\n",
    "    labels.append(str(x.date()))\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), dpi = 300)\n",
    "\n",
    "l1 = plt.plot(x_pos, grouped['trialid'], marker = 'o')\n",
    "l2 = plt.plot(x_pos, cumsum['trialid'], marker = 'o')\n",
    "\n",
    "for i, j in zip(x_pos[1:], grouped['trialid'].tolist()[1:]):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.1, j-35))\n",
    "\n",
    "for i, j in zip(x_pos, cumsum['trialid']):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.2, j+20))\n",
    "    \n",
    "\n",
    "gr = grouped['trialid'].to_list()\n",
    "cs = cumsum['trialid'].to_list()\n",
    "\n",
    "plt.xticks(x_pos, labels, rotation=45, fontsize=8)\n",
    "plt.ylim(-20,600)\n",
    "plt.xlabel('Week Ending Date')\n",
    "plt.ylabel('Registered Trials')\n",
    "plt.title('Registered COVID-19 Trials by Week on the ICTRP')\n",
    "plt.legend(('New Trials', 'Cumulative Trials'), loc=2)\n",
    "#plt.savefig(f'trial_count_{last_extract_date}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
